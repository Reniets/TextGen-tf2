{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextGen_tf2pub.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Derh_z5xRc4H"
      },
      "source": [
        "Copyright 2019 Almintas Povilaitis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fm-HVp5SRDa7"
      },
      "source": [
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gXnXsnMyYPUV"
      },
      "source": [
        "## Prep work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yUjjttgRYWI9"
      },
      "source": [
        "### Download relevant libraries and check the setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RjnAX03nXbWn",
        "outputId": "42170cc6-8aef-4daa-e42f-3fb1df97da1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install tensorflow-gpu==2.0.0-alpha0\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n",
            "\u001b[K     |████████████████████████████████| 332.1MB 34kB/s \n",
            "\u001b[?25hCollecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow-gpu==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow-gpu==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 48.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.16.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.7)\n",
            "Collecting google-pasta>=0.1.2 (from tensorflow-gpu==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/68/a14620bfb042691f532dcde8576ff82ee82e4c003cdc0a3dbee5f289cee6/google_pasta-0.1.6-py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 28.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.9)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, google-pasta, tensorflow-gpu\n",
            "Successfully installed google-pasta-0.1.6 tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "asvI4tVjXob-",
        "outputId": "b837f485-c8ca-4512-bf61-92aa5e9b3ff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"TensorFlow version: \", tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version:  2.0.0-alpha0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5tSAEtZsZXlJ"
      },
      "source": [
        "Check if GPU is available - always good to double-check. When using Colab, I sometimes forget to change runtime type, so having this  code will always catch it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "He4OvefpZMr6",
        "outputId": "cb0510c2-5c8a-4e84-9f06-bfd0e0ed871f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 3435799257259448661\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 3011604498538087361\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 4756490919112881296\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14892338381\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 1477902680324503869\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MYMrkgt9X1t_"
      },
      "source": [
        "If need to remove logs from previous runs, uncomment and adjust the directory name:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8xT0uOUoXued",
        "colab": {}
      },
      "source": [
        "#!rm -rf ./checkpoints_2019.04.21-20:48:58/ #if using Tensorboard or other logging"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LamqnzOZYsu7"
      },
      "source": [
        "### Download the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nU0wJvJlFGv",
        "colab_type": "text"
      },
      "source": [
        "Check the current directory and upload the text file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MD49SegeY46C",
        "outputId": "e4b22ead-4e27-4cda-e3e3-7f4c3d8e87ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "path = os.getcwd()\n",
        "print(path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3eflFyPIZ21J",
        "outputId": "da993ac5-ac2e-4544-aefb-a659f7126d0f",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "# if using Google Colab\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Click Files tab - the updload file(s) will be there"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bb391bcf-2475-4d36-905e-e9aa41232372\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-bb391bcf-2475-4d36-905e-e9aa41232372\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dhmPv312ej5X"
      },
      "source": [
        "In case you have multiple files that need to be merged:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Diu-RxbycCnQ",
        "outputId": "4daabbb9-4a60-4b2c-d60d-8e8276422898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#If using a directory with multiple files\n",
        "import glob\n",
        "import codecs\n",
        "books = sorted(glob.glob(path + \"/*.txt\"))\n",
        "print(\"Found {} books\".format(len(books)))\n",
        "\n",
        "text = \"\"\n",
        "for filename in books:\n",
        "    with codecs.open(filename, 'r', 'utf-8') as books:\n",
        "        text += books.read()\n",
        "\n",
        "print(\"Text is {} characters long\".format(len(text)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1 books\n",
            "Text is 886809 characters long\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ITkDCoKndL3k",
        "outputId": "10914546-cce0-4189-cac5-160218516acd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#If using a single file\n",
        "text = open(path + '/Iliad_v3.txt', 'rb').read().decode(encoding='utf-8')\n",
        "print(\"Text is {} characters long\".format(len(text)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text is 886809 characters long\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y9pruxZJXlkX",
        "outputId": "05abf976-6a69-44fc-e417-b4970f3248bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "words = [w for w in text.split(' ') if w.strip() != '' or w == '\\n']\n",
        "print(\"Text is {} words long\".format(len(words)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text is 153260 words long\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6haqpbyNahWL"
      },
      "source": [
        "Make sure the text sample is what you expected:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gdrWeIZCac2b",
        "outputId": "28ef0be4-7ddb-4d2b-c11c-898374358bd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(text[:100])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  achilles' wrath, to greece the direful spring\n",
            "  of woes unnumber'd, heavenly goddess, sing!\n",
            "  that\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YKI0wsZne8o9"
      },
      "source": [
        "## Prepare the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AgcMBNHxfn4D",
        "outputId": "67774f25-be94-42bf-830a-948b6be5d35a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "source": [
        "#Map unique characters to indices\n",
        "vocab = sorted(set(text))\n",
        "print ('There are {} unique characters'.format(len(vocab)))\n",
        "char2int = {c:i for i, c in enumerate(vocab)}\n",
        "int2char = np.array(vocab)\n",
        "print('Vector:\\n')\n",
        "for char,_ in zip(char2int, range(len(vocab))):\n",
        "   print(' {:4s}: {:3d},'.format(repr(char), char2int[char]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 34 unique characters\n",
            "Vector:\n",
            "\n",
            " '\\n':   0,\n",
            " ' ' :   1,\n",
            " '!' :   2,\n",
            " \"'\" :   3,\n",
            " ',' :   4,\n",
            " '-' :   5,\n",
            " '.' :   6,\n",
            " '?' :   7,\n",
            " 'a' :   8,\n",
            " 'b' :   9,\n",
            " 'c' :  10,\n",
            " 'd' :  11,\n",
            " 'e' :  12,\n",
            " 'f' :  13,\n",
            " 'g' :  14,\n",
            " 'h' :  15,\n",
            " 'i' :  16,\n",
            " 'j' :  17,\n",
            " 'k' :  18,\n",
            " 'l' :  19,\n",
            " 'm' :  20,\n",
            " 'n' :  21,\n",
            " 'o' :  22,\n",
            " 'p' :  23,\n",
            " 'q' :  24,\n",
            " 'r' :  25,\n",
            " 's' :  26,\n",
            " 't' :  27,\n",
            " 'u' :  28,\n",
            " 'v' :  29,\n",
            " 'w' :  30,\n",
            " 'x' :  31,\n",
            " 'y' :  32,\n",
            " 'z' :  33,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ypjqjoHEfJXg",
        "outputId": "fe6a173b-3393-46c3-f993-e56f21348a23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "text_as_int = np.array([char2int[ch] for ch in text], dtype=np.int32)\n",
        "print ('{}\\n mapped to integers:\\n {}'.format(repr(text[:100]), text_as_int[:100]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"  achilles' wrath, to greece the direful spring\\n  of woes unnumber'd, heavenly goddess, sing!\\n  that\"\n",
            " mapped to integers:\n",
            " [ 1  1  8 10 15 16 19 19 12 26  3  1 30 25  8 27 15  4  1 27 22  1 14 25\n",
            " 12 12 10 12  1 27 15 12  1 11 16 25 12 13 28 19  1 26 23 25 16 21 14  0\n",
            "  1  1 22 13  1 30 22 12 26  1 28 21 21 28 20  9 12 25  3 11  4  1 15 12\n",
            "  8 29 12 21 19 32  1 14 22 11 11 12 26 26  4  1 26 16 21 14  2  0  1  1\n",
            " 27 15  8 27]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-FBpLzLYsqCb",
        "colab": {}
      },
      "source": [
        "tr_text = text_as_int[:704000] #text separated for training, divisible by the batch size (64)\n",
        "val_text = text_as_int[704000:] #text separated for validation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2gB2GHvvga26"
      },
      "source": [
        "Comfirm the shapes are what we expect:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1DU6Dwj8hEtI",
        "outputId": "54a9ee40-be9b-4570-e231-645b494f6b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(text_as_int.shape, tr_text.shape, val_text.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(886809,) (704000,) (182809,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uZZLCyTNHONf"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wy5yl7d2heq6",
        "colab": {}
      },
      "source": [
        "# Populate the library of tunables - I like keeping the centralized in case I need to change things around:\n",
        "batch_size = 64\n",
        "buffer_size = 10000\n",
        "embedding_dim = 256\n",
        "epochs = 50\n",
        "seq_length = 200\n",
        "examples_per_epoch = len(text)//seq_length\n",
        "#lr = 0.001 #will use default for Adam optimizer\n",
        "rnn_units = 1024\n",
        "vocab_size = len(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1e9_DLdGsqC0",
        "outputId": "e1760804-fb1a-4785-ee18-8744d56a5605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "tr_char_dataset = tf.data.Dataset.from_tensor_slices(tr_text)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices(val_text)\n",
        "print(tr_char_dataset, val_char_dataset)\n",
        "tr_sequences = tr_char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "val_sequences = val_char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "print(tr_sequences, val_sequences)\n",
        "\n",
        "for item in tr_sequences.take(1):\n",
        "    print(repr(''.join(int2char[item.numpy()])))\n",
        "    print(item)\n",
        "for item in val_sequences.take(1):\n",
        "    print(repr(''.join(int2char[item.numpy()])))\n",
        "    print(item)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<TensorSliceDataset shapes: (), types: tf.int32> <TensorSliceDataset shapes: (), types: tf.int32>\n",
            "<BatchDataset shapes: (201,), types: tf.int32> <BatchDataset shapes: (201,), types: tf.int32>\n",
            "\"  achilles' wrath, to greece the direful spring\\n  of woes unnumber'd, heavenly goddess, sing!\\n  that wrath which hurl'd to pluto's gloomy reign\\n  the souls of mighty chiefs untimely slain \\n  whose limb\"\n",
            "tf.Tensor(\n",
            "[ 1  1  8 10 15 16 19 19 12 26  3  1 30 25  8 27 15  4  1 27 22  1 14 25\n",
            " 12 12 10 12  1 27 15 12  1 11 16 25 12 13 28 19  1 26 23 25 16 21 14  0\n",
            "  1  1 22 13  1 30 22 12 26  1 28 21 21 28 20  9 12 25  3 11  4  1 15 12\n",
            "  8 29 12 21 19 32  1 14 22 11 11 12 26 26  4  1 26 16 21 14  2  0  1  1\n",
            " 27 15  8 27  1 30 25  8 27 15  1 30 15 16 10 15  1 15 28 25 19  3 11  1\n",
            " 27 22  1 23 19 28 27 22  3 26  1 14 19 22 22 20 32  1 25 12 16 14 21  0\n",
            "  1  1 27 15 12  1 26 22 28 19 26  1 22 13  1 20 16 14 15 27 32  1 10 15\n",
            " 16 12 13 26  1 28 21 27 16 20 12 19 32  1 26 19  8 16 21  1  0  1  1 30\n",
            " 15 22 26 12  1 19 16 20  9], shape=(201,), dtype=int32)\n",
            "\"e white-arm'd queen survey'd,\\n  and thus, assembling all the powers, she said \\n   behold an action, gods! that claims your care,\\n  lo great  neas rushing to the war!\\n  against pelides he directs his co\"\n",
            "tf.Tensor(\n",
            "[12  1 30 15 16 27 12  5  8 25 20  3 11  1 24 28 12 12 21  1 26 28 25 29\n",
            " 12 32  3 11  4  0  1  1  8 21 11  1 27 15 28 26  4  1  8 26 26 12 20  9\n",
            " 19 16 21 14  1  8 19 19  1 27 15 12  1 23 22 30 12 25 26  4  1 26 15 12\n",
            "  1 26  8 16 11  1  0  1  1  1  9 12 15 22 19 11  1  8 21  1  8 10 27 16\n",
            " 22 21  4  1 14 22 11 26  2  1 27 15  8 27  1 10 19  8 16 20 26  1 32 22\n",
            " 28 25  1 10  8 25 12  4  0  1  1 19 22  1 14 25 12  8 27  1  1 21 12  8\n",
            " 26  1 25 28 26 15 16 21 14  1 27 22  1 27 15 12  1 30  8 25  2  0  1  1\n",
            "  8 14  8 16 21 26 27  1 23 12 19 16 11 12 26  1 15 12  1 11 16 25 12 10\n",
            " 27 26  1 15 16 26  1 10 22], shape=(201,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1Asy0RHPFzsc",
        "outputId": "c2869143-249e-4530-8a0f-a4ee23e6e0a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "tr_dataset = tr_sequences.map(split_input_target).shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
        "val_dataset = val_sequences.map(split_input_target).shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
        "print(tr_dataset, val_dataset)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: ((64, 200), (64, 200)), types: (tf.int32, tf.int32)> <BatchDataset shapes: ((64, 200), (64, 200)), types: (tf.int32, tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7Ta6TWbuF7Fx",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.Dropout(0.2), \n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dXyjPJ1oG_N3",
        "outputId": "14ae9863-7a18-40fc-8169-b075c1705442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "model = build_model(\n",
        "    vocab_size = len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=batch_size)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0511 11:24:57.663641 139886039209856 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f3929fdad30>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "W0511 11:24:57.673140 139886039209856 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f3929fde588>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6qLDewlkHcP4"
      },
      "source": [
        "## Run the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FwAn1CzeHu3m"
      },
      "source": [
        "Check the output shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nkUviDjkHHkl",
        "outputId": "a8512eb5-aaca-447c-bf8d-84bb19813e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for input_example_batch, target_example_batch in tr_dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 200, 34) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LtEcXnYhHyVz",
        "outputId": "1eb3e1f7-9da9-430a-c26c-bf0ede4aaa31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           8704      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (64, None, 256)           0         \n",
            "_________________________________________________________________\n",
            "unified_lstm (UnifiedLSTM)   (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (64, None, 1024)          0         \n",
            "_________________________________________________________________\n",
            "unified_lstm_1 (UnifiedLSTM) (64, None, 1024)          8392704   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (64, None, 1024)          0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 34)            34850     \n",
            "=================================================================\n",
            "Total params: 13,683,234\n",
            "Trainable params: 13,683,234\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tYGhrBXKIM4x"
      },
      "source": [
        "Untrained model output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qq-g-DmKIBkp",
        "outputId": "c27ff7e9-0db0-4f8f-c42f-cd4e649668b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "print(\"Input: \\n\", repr(\"\".join(int2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Predictions: \\n\", repr(\"\".join(int2char[sampled_indices ])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " \"oul incite\\n  to dare the boldest greek to single fight,\\n  till greece, provoked, from all her numbers show\\n  a warrior worthy to be hector's foe. \\n  at this agreed, the heavenly powers withdrew \\n  sag\"\n",
            "\n",
            "Predictions: \n",
            " \"!ro.,xm.g.gsafxa?\\na,jy-,m,zcgx ,c?luqc.!wpp.ape,-mdptb!?cklh,?q,cx,qbzz u.mypco-nswugeo!senzh!xfsyw.\\nk  qefxqjxpvxpfbp\\n.x?sutmkcjw -yg\\ncpf'-!,yrzj,-rv?g?.ackvzmcpafq,!k-ycxg-i''\\niugjo-q,th-?r urh.fuql\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u744e_goIOzP",
        "outputId": "85524304-d144-4309-8260-99ee59f6ecf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "def accuracy(labels, logits):\n",
        "    return tf.keras.metrics.sparse_categorical_accuracy(labels, logits)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "example_batch_acc  = accuracy(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Loss:      \", example_batch_loss.numpy().mean())\n",
        "print(\"Accuracy:      \", example_batch_acc.numpy().mean())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 200, 34)  # (batch_size, sequence_length, vocab_size)\n",
            "Loss:       3.5259674\n",
            "Accuracy:       0.0265625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DEvIj65tIshz",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam() #also can use \"Adam(lr=lr)\"\n",
        "model.compile(optimizer=optimizer, loss=loss) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QDzNCe8YSeXY",
        "colab": {}
      },
      "source": [
        "patience = 10\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gEGtTQMKJdgo",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './checkpoints'+ datetime.datetime.now().strftime(\"_%Y.%m.%d-%H:%M:%S\")\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m-o-W4MXI115",
        "outputId": "86f6a6ab-5a87-491c-d683-d85263c532db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        }
      },
      "source": [
        "history = model.fit(tr_dataset, epochs=epochs, callbacks=[checkpoint_callback, early_stop] , validation_data=val_dataset)\n",
        "print (\"Training stopped as there was no improvement after {} epochs\".format(patience))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 2.9989 - val_loss: 2.7497\n",
            "Epoch 2/50\n",
            "54/54 [==============================] - 24s 440ms/step - loss: 2.5684 - val_loss: 2.3544\n",
            "Epoch 3/50\n",
            "54/54 [==============================] - 23s 422ms/step - loss: 2.2080 - val_loss: 2.0650\n",
            "Epoch 4/50\n",
            "54/54 [==============================] - 24s 438ms/step - loss: 1.9669 - val_loss: 1.8601\n",
            "Epoch 5/50\n",
            "54/54 [==============================] - 24s 443ms/step - loss: 1.7792 - val_loss: 1.7005\n",
            "Epoch 6/50\n",
            "54/54 [==============================] - 23s 430ms/step - loss: 1.6317 - val_loss: 1.5791\n",
            "Epoch 7/50\n",
            "54/54 [==============================] - 23s 434ms/step - loss: 1.5165 - val_loss: 1.4870\n",
            "Epoch 8/50\n",
            "54/54 [==============================] - 24s 438ms/step - loss: 1.4286 - val_loss: 1.4219\n",
            "Epoch 9/50\n",
            "54/54 [==============================] - 24s 436ms/step - loss: 1.3604 - val_loss: 1.3722\n",
            "Epoch 10/50\n",
            "54/54 [==============================] - 23s 435ms/step - loss: 1.3073 - val_loss: 1.3364\n",
            "Epoch 11/50\n",
            "54/54 [==============================] - 24s 435ms/step - loss: 1.2620 - val_loss: 1.3124\n",
            "Epoch 12/50\n",
            "54/54 [==============================] - 24s 437ms/step - loss: 1.2219 - val_loss: 1.2943\n",
            "Epoch 13/50\n",
            "54/54 [==============================] - 24s 435ms/step - loss: 1.1869 - val_loss: 1.2813\n",
            "Epoch 14/50\n",
            "54/54 [==============================] - 24s 436ms/step - loss: 1.1534 - val_loss: 1.2736\n",
            "Epoch 15/50\n",
            "54/54 [==============================] - 24s 439ms/step - loss: 1.1211 - val_loss: 1.2656\n",
            "Epoch 16/50\n",
            "54/54 [==============================] - 24s 438ms/step - loss: 1.0889 - val_loss: 1.2641\n",
            "Epoch 17/50\n",
            "54/54 [==============================] - 24s 436ms/step - loss: 1.0556 - val_loss: 1.2691\n",
            "Epoch 18/50\n",
            "54/54 [==============================] - 24s 436ms/step - loss: 1.0234 - val_loss: 1.2782\n",
            "Epoch 19/50\n",
            "54/54 [==============================] - 23s 435ms/step - loss: 0.9942 - val_loss: 1.2918\n",
            "Epoch 20/50\n",
            "54/54 [==============================] - 24s 436ms/step - loss: 0.9600 - val_loss: 1.2996\n",
            "Epoch 21/50\n",
            "54/54 [==============================] - 24s 439ms/step - loss: 0.9263 - val_loss: 1.3144\n",
            "Epoch 22/50\n",
            "54/54 [==============================] - 24s 436ms/step - loss: 0.8956 - val_loss: 1.3337\n",
            "Epoch 23/50\n",
            "54/54 [==============================] - 24s 436ms/step - loss: 0.8602 - val_loss: 1.3493\n",
            "Epoch 24/50\n",
            "54/54 [==============================] - 24s 438ms/step - loss: 0.8298 - val_loss: 1.3746\n",
            "Epoch 25/50\n",
            "54/54 [==============================] - 24s 438ms/step - loss: 0.7959 - val_loss: 1.4040\n",
            "Epoch 26/50\n",
            "54/54 [==============================] - 24s 437ms/step - loss: 0.7631 - val_loss: 1.4312\n",
            "Training stopped as there was no improvement after 10 epochs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_sluYs8sJW5Y",
        "outputId": "ee0297b6-743c-4863-ad45-62169d3700c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,9))\n",
        "plt.plot(history.history['loss'], 'g')\n",
        "plt.plot(history.history['val_loss'], 'rx') #use if have val data\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='upper right')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right') #use if have val date\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAImCAYAAABzdx3iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAEAcCNQAAABAHP4fsdv6MFeJ9coAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WWDBRn1rJ-FT"
      },
      "source": [
        "## Generate text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u0UHhaktJ9Da",
        "outputId": "23bbd918-695d-4021-c32e-462f0edac422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./checkpoints_2019.05.11-11:28:57/ckpt_26'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GRp4fBGWKPew",
        "outputId": "33e032a6-be6c-450b-b9f9-1a86e36bcac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "#model.load_weights('./checkpoints_2019.04.29-00:31:15/ckpt_17')  #if the latest checkpoint is not your preferred\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))  #if the latest checkpoint is what you want\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0511 11:44:34.060273 139886039209856 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f391251ec18>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "W0511 11:44:34.065123 139886039209856 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f39124b9978>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 256)            8704      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (1, None, 256)            0         \n",
            "_________________________________________________________________\n",
            "unified_lstm_2 (UnifiedLSTM) (1, None, 1024)           5246976   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (1, None, 1024)           0         \n",
            "_________________________________________________________________\n",
            "unified_lstm_3 (UnifiedLSTM) (1, None, 1024)           8392704   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (1, None, 1024)           0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 34)             34850     \n",
            "=================================================================\n",
            "Total params: 13,683,234\n",
            "Trainable params: 13,683,234\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E4wEjZn6KYSZ",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "    \n",
        "    print('Generating with seed: \"' + start_string + '\"')\n",
        "  \n",
        "  # Number of characters to generate\n",
        "    num_generate = 1000\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "    input_eval = [char2int[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    text_generated = []\n",
        "\n",
        "    temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the word returned by the model\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted word as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(int2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XvBbck9MK0Cb",
        "outputId": "73041393-7680-4ecb-d925-9de810ccc2b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "print(generate_text(model, start_string=\"joy of gods\"))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating with seed: \"joy of gods\"\n",
            "joy of gods! he said \n",
            "  then be what spear, by warriors to thy friend,\n",
            "  with equal train distain'd the beether's ble,\n",
            "  between his eyes and mortal mix impent!\n",
            "   is this the god of jove. without thy throne,\n",
            "  great partial deeps in end thine milds contern \n",
            "  amidst his conquering eyebellows,\n",
            "  in yield tast the impending fate. were steed,\n",
            "  and or may great, and great ulysses draws,\n",
            "  and thick avenge his arted eyes beheld,\n",
            "  light, horror, piercing through the gloomy shade. \n",
            "  steop'd with a rock, nor this celestial crowd,\n",
            "  and shoot the swain and sees of their exking undended eloms with force.\n",
            "  now, bring their hearts be bore a hero boree\n",
            "  it rises, and his whole fame can save,\n",
            "  or bore the kings of heaven, with shall detire,\n",
            "  that moves and one has cause thee, and departs.\n",
            "  the strokes approach my conquering troops putue.\n",
            "  swift as the wind, within the steeds prepare.\n",
            "  god of atrides, spare their heroes slain \n",
            "  let fierce defend the e conduct of a god. \n",
            "  these to the sears a swart \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZiBHrzctK3Ap",
        "outputId": "d9721bbf-2bb0-4b2c-890b-86c7c9eecbfe",
        "colab": {}
      },
      "source": [
        "with open('sampleTF2.txt', 'w') as f:\n",
        "    sampleTF2 = generate_text(model, start_string=\"people rising\")\n",
        "    f.write(sampleTF2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating with seed: \"people rising\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FQiEPW1usqD4"
      },
      "source": [
        "Free memory resources if needed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IbhTRpUsL3Bg",
        "colab": {}
      },
      "source": [
        "import signal\n",
        "\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}